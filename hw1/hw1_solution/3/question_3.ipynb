{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# Constants\n",
    "IN_FILENAME = 'AP_train.txt'\n",
    "\n",
    "# Helper functions\n",
    "def read_file(in_filename=IN_FILENAME, nrows=None):\n",
    "    for line in open(IN_FILENAME):\n",
    "        if nrows is None:\n",
    "            yield line\n",
    "        elif nrows == 0:\n",
    "            return\n",
    "        else:\n",
    "            nrows -= 1\n",
    "            yield line\n",
    "\n",
    "def summary_statistics(data_points):\n",
    "    def quartiles(numbers):\n",
    "        sorted_numbers = sorted(numbers)\n",
    "        mid = len(sorted_numbers) // 2 # uses the floor division to have integer returned\n",
    "        if (len(sorted_numbers) % 2 == 0):\n",
    "            # even\n",
    "            lowerQ = statistics.median(sorted_numbers[:mid])\n",
    "            upperQ = statistics.median(sorted_numbers[mid:])\n",
    "        else:\n",
    "            # odd\n",
    "            lowerQ = statistics.median(sorted_numbers[:mid])\n",
    "            upperQ = statistics.median(sorted_numbers[mid+1:])\n",
    "        return (lowerQ, upperQ)\n",
    "    mean = statistics.mean(data_points)\n",
    "    sd = statistics.stdev(data_points)\n",
    "    median = statistics.median(data_points)\n",
    "    q1, q3 = quartiles(data_points)\n",
    "    print('Mean: {}'.format(mean))\n",
    "    print('Standard Deviation: {}'.format(sd))\n",
    "    print('Median: {}'.format(median))\n",
    "    print('1st Quartile: {}'.format(q1))\n",
    "    print('3rd Quartile: {}'.format(q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#index', '1']\n",
      "['#*', 'Book Review: Discover Linux']\n",
      "['#@', 'Marjorie Richardson']\n",
      "['#t', '1998']\n",
      "['#c', 'Linux Journal']\n",
      "['']\n",
      "['#index', '2']\n",
      "['#*', 'MOSFET table look-up models for circuit simulation']\n",
      "['#@']\n",
      "['#t', '1984']\n"
     ]
    }
   ],
   "source": [
    "# Explore dataset\n",
    "for line in read_file(nrows=10):\n",
    "    print(line.strip().split(' ', 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Counts:\n",
    "\n",
    "**a. Compute the number of distinct authors, publication venues, publications, and citations/references**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures:\n",
    "authors = set()\n",
    "publication_venues = set()\n",
    "publications = set()\n",
    "citations = set()\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def process_authors(authors_string):\n",
    "    auth = authors_string.strip().split(';')\n",
    "    auth = set([a.strip() for a in auth])\n",
    "    authors.update(auth)\n",
    "\n",
    "def process_citation(index, citation_string):\n",
    "    citation = index + ' ' + citation_string\n",
    "    citations.add(citation)\n",
    "    \n",
    "# Script\n",
    "index = 0\n",
    "for line in read_file():\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#index':\n",
    "            index = line[1].strip()\n",
    "            publications.add(index)\n",
    "        elif line[0] == '#@':\n",
    "            process_authors(line[1].strip())\n",
    "        elif line[0] == '#c':\n",
    "            publication_venues.add(line[1].strip())\n",
    "        elif line[0] == '#%':\n",
    "            process_citation(index, line[1].strip())\n",
    "    except IndexError:\n",
    "        continue\n",
    "        \n",
    "print('Number of distinct authors: {}'.format(len(authors)))\n",
    "print('Number of distinct publication venues: {}'.format(len(publication_venues)))\n",
    "print('Number of distinct publications: {}'.format(len(publications)))\n",
    "print('Number of distinct citations: {}'.format(len(citations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Are these numbers likely to be accurate? As an example look up all the publications venue names associated with the conference “Principles and Practice of Knowledge Discovery in Databases” – what do you notice?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_venues = set()\n",
    "for line in read_file():\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#c' and 'Principles and Practice of Knowledge Discovery in Databases' in line[1]:\n",
    "            publication_venues.add(line[1].strip())\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "for i, pv in enumerate(publication_venues):\n",
    "    print(i, pv)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in item a. are not likely to be accurate. For example, the same publication venue might be named a little differently each time as seen above, or the same author might be repeated in the dataset with their shortened or full names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Publications, Authors, Venues\n",
    "\n",
    "**a. For each author, construct the list of publications. Plot a histogram of the number of publications per author (use a logarithmic scale on the y axis).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "author_publications = defaultdict(list)\n",
    "\n",
    "# Helper functions\n",
    "def get_authors(authors_string):\n",
    "    auth = authors_string.strip().split(';')\n",
    "    auth = set([a.strip() for a in auth])\n",
    "    return auth\n",
    "    \n",
    "# Script\n",
    "index = 0\n",
    "for line in read_file(nrows=None):\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#index':\n",
    "            index = line[1].strip()\n",
    "        elif line[0] == '#@':\n",
    "            authors = get_authors(line[1].strip())\n",
    "            for author in authors:\n",
    "                author_publications[author].append(index)\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "num_pubs_per_author = [len(v) for k, v in author_publications.items()]\n",
    "plt.hist(num_pubs_per_author, bins=50, log=True)\n",
    "plt.title('Number of publications per author')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Calculate the mean and standard deviation of the number of publications per author. Also calculate the Q1 (1st quartile), Q2 (2nd quartile, or median) and Q3 (3rd quartile) values. Compare the median to the mean and explain the difference between the two values based on the standard deviation and the 1st and 3rd quartiles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Summary\n",
    "print('Summary for the number of publications per author:')\n",
    "summary_statistics(num_pubs_per_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the above summary statistics, we see that the mean is greater than the 3rd quartile. This shows that the value of the mean is being shifted to the right due to outliers having a high value. Hence, for this dataset, the median is a better approximation of the average number of publications per author than the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. Now plot a histogram of the number of publications per venue, as well as calculate the mean, standard deviation, median, Q1, and Q3 values. What is the venue with the largest number of publications in the dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "venue_publications = defaultdict(list)\n",
    "    \n",
    "    \n",
    "# Script\n",
    "index = 0\n",
    "for line in read_file():\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#index':\n",
    "            index = line[1].strip()\n",
    "        elif line[0] == '#c':\n",
    "            venue = line[1].strip()\n",
    "            venue_publications[venue].append(index)\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "# Histogram        \n",
    "num_pubs_per_venue = [len(v) for k, v in venue_publications.items()]\n",
    "plt.hist(num_pubs_per_venue, bins=50, log=True)\n",
    "plt.show()\n",
    "\n",
    "# Statistical Summary\n",
    "print('Summary for the number of publications per venue:')\n",
    "summary_statistics(num_pubs_per_venue)\n",
    "\n",
    "# Venue with the largest number of publications\n",
    "max_venue = max(venue_publications, key=lambda x:len(venue_publications[x]))\n",
    "print('Venue with the largest number of publications: {}'.format(max_venue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References, Citations, Impact\n",
    "\n",
    "**a. Plot a histogram of the number of references (number of publications a publication refers to) and citations (number of publications referring to a publication) per publication. What is the publication with the largest number of references? What is the publication with the largest number of citations? Do these make sense?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "pub_references = defaultdict(list)\n",
    "pub_citations = defaultdict(list)\n",
    "    \n",
    "# Script\n",
    "index = 0\n",
    "for line in read_file():\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#index':\n",
    "            index = line[1].strip()\n",
    "        elif line[0] == '#%':\n",
    "            reference = line[1].strip()\n",
    "            pub_references[index].append(reference)\n",
    "            pub_citations[reference].append(index)\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "# Histograms      \n",
    "num_refs_per_pub = [len(v) for k, v in pub_references.items()]\n",
    "plt.hist(num_refs_per_pub, bins=50, log=True)\n",
    "plt.title('Number of references per publication')\n",
    "plt.show()\n",
    "\n",
    "num_cits_per_pub = [len(v) for k, v in pub_citations.items()]\n",
    "plt.hist(num_cits_per_pub, bins=50, log=True)\n",
    "plt.title('Number of citations per publication')\n",
    "plt.show()\n",
    "\n",
    "# Publication with the largest number of references\n",
    "max_references = max(pub_references, key=lambda x:len(pub_references[x]))\n",
    "print('Publication with the largest number of references: {}'.format(max_references))        \n",
    "\n",
    "# Publication with the largest number of citations\n",
    "max_citations = max(pub_citations, key=lambda x:len(pub_citations[x]))\n",
    "print('Publication with the largest number of citations: {}'.format(max_citations))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me, it's hard to fathom a publication that has 719353 references. However, a publication having 408396 citations seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Calculate the so called “impact” factor for each venue. To do so, calculate the total number of citations for the publications in the venue, and then divide this number by the number of publications for the venue. Plot a histogram of the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "venue_impact = defaultdict(list)\n",
    "    \n",
    "\n",
    "# Script\n",
    "for venue, publications in venue_publications.items():\n",
    "    impact = sum([len(pub_citations[pub]) for pub in publications]) / float(len(publications))\n",
    "    venue_impact[venue] = impact\n",
    "\n",
    "# Histogram\n",
    "plt.hist(list(venue_impact.values()), bins=50, log=True)\n",
    "plt.title('Impact factor of venues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. What is the venue with the highest apparent impact factor? Do you believe this number?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Venue with the highest apparent impact factor\n",
    "max_impact_venue = max(venue_impact, key=lambda x:venue_impact[x])\n",
    "print('Venue with the highest apparent impact factor: {}'.format(max_impact_venue))        \n",
    "print('Max impact factor: {}'.format(venue_impact[max_impact_venue]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The maximum impact factor as seen above seems unreasonably high to be believable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Now repeat the calculation from item b., but restrict the calculation to venues with at least 10 publications. How does your histogram change? List the citation counts for all publications from the venue with the highest impact factor. How does the impact factor (mean number of citations) compare to the median number of citations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "venue_impact = defaultdict(float)\n",
    "    \n",
    "# Script\n",
    "for venue, publications in venue_publications.items():\n",
    "    if len(publications) >= 10:\n",
    "        impact = sum([len(pub_citations[pub]) for pub in publications]) / float(len(publications))\n",
    "        venue_impact[venue] = impact\n",
    "\n",
    "# Histogram\n",
    "plt.hist(list(venue_impact.values()), bins=50, log=True)\n",
    "plt.title('Impact factor of venues with at least 10 publications')\n",
    "plt.show()\n",
    "\n",
    "# Venue with the highest apparent impact factor\n",
    "max_impact_venue = max(venue_impact, key=lambda x:venue_impact[x])\n",
    "print('Citation counts for publications at venue: {}'.format(max_impact_venue))\n",
    "for pub in venue_publications[max_impact_venue]:\n",
    "      print('{} : {}'.format(pub, len(pub_citations[pub])))\n",
    "\n",
    "# Mean and Median number of citations for the venue with the highest apparent impact factor\n",
    "median = statistics.median(([len(pub_citations[pub]) for pub in venue_publications[max_impact_venue]]))\n",
    "print('\\nMean/Impact factor of citations for venue {} : {}'.format(max_impact_venue, venue_impact[max_impact_venue]))\n",
    "print('Median number of citations for venue {} : {}'.format(max_impact_venue, median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e. Finally, construct a list of publications for each publication year. Use this list to plot the average number of references and average number of citations per publication as a function of time. Explain the differences you see in the trends.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures\n",
    "year_publications = defaultdict(list)\n",
    "year_avg_ref = defaultdict(float)\n",
    "year_avg_cit = defaultdict(float)\n",
    "\n",
    "# Script\n",
    "index = 0\n",
    "for line in read_file():\n",
    "    line = line.strip().split(' ', 1)\n",
    "    try:\n",
    "        if line[0] == '#index':\n",
    "            index = line[1].strip()\n",
    "        elif line[0] == '#t':\n",
    "            year = line[1].strip()\n",
    "            year_publications[year].append(index)\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "for year, publications in year_publications.items():\n",
    "    year_avg_ref[year] = sum([len(pub_references[pub]) for pub in publications]) / float(len(publications))\n",
    "    year_avg_cit[year] = sum([len(pub_citations[pub]) for pub in publications]) / float(len(publications))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the avg number of references and citations per year\n",
    "x = sorted(year_publications)\n",
    "y1 = [year_avg_ref[year] for year in x]\n",
    "y2 = [year_avg_cit[year] for year in x]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y1, 'g^', label='Avg number of references')\n",
    "ax.plot(x, y2, 'b^', label='Avg number of citations')\n",
    "legend = ax.legend(loc='upper center', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
